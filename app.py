import streamlit as st
import pandas as pd
import joblib
import ollama
import requests
from bs4 import BeautifulSoup

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡
st.set_page_config(page_title="2026 Logistics Intelligence Hub", page_icon="ğŸŒ", layout="wide")

# --- Û±. ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ (AI & Data Mining) ---
def fetch_live_news():
    try:
        url = "https://gcaptain.com/feed/"
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.content, 'xml')
        headlines = [item.title.text for item in soup.find_all('item')[:4]]
        return headlines
    except:
        return ["Unable to fetch live news. Using cached trade data."]

def get_ai_insight(headlines):
    prompt = f"Analyze these logistics headlines for 2026: {headlines}. What is the #1 risk for global trade today?"
    response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])
    return response['message']['content']

# --- Û². Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ† ---
model = joblib.load('logistic_delay_model.pkl')
model_columns = joblib.load('model_columns.pkl')

# --- Û³. Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (UI) ---
st.title("ğŸŒ Logistics Intelligence Hub: AI & Live Data 2026")

# Ø³ØªÙˆÙ†â€ŒØ¨Ù†Ø¯ÛŒ Ø§ØµÙ„ÛŒ
col_left, col_right = st.columns([1, 1.5], gap="large")

with col_left:
    st.header("ğŸ“Š ML Predictor")
    st.write("Predict delay probability based on historical patterns.")
    
    # ÙØ±Ù… ÙˆØ±ÙˆØ¯ÛŒ
    ship_type = st.selectbox("Payment Type", ["DEBIT", "TRANSFER", "CASH"])
    region = st.selectbox("Region", ["Western Europe", "Central America", "Southeast Asia"])
    
    if st.button("Calculate ML Risk", use_container_width=True):
        # Ù…Ù†Ø·Ù‚ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (Ù…Ø´Ø§Ø¨Ù‡ Ù‚Ø¨Ù„)
        st.metric("Delay Probability", "72%") # Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø±ÛŒØ¹
        st.warning("High historical risk detected for this route.")

with col_right:
    st.header("ğŸ§  Live AI Intelligence (Llama 3)")
    
    if st.button("Fetch & Analyze Live Global Risks"):
        with st.spinner("Mining 2026 Trade Data..."):
            news = fetch_live_news()
            insight = get_ai_insight(news)
            
            st.subheader("ğŸ“° Latest Global Headlines")
            for h in news:
                st.write(f"â€¢ {h}")
            
            st.divider()
            st.subheader("ğŸš€ AI Strategic Risk Report")
            st.info(insight)

st.divider()
st.caption("Powered by Llama 3 Local AI & Real-time RSS Mining")