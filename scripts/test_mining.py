# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup

def test_fetch_rss():
    print("ğŸŒ Connecting to gCaptain Logistics RSS Feed...")
    # RSS Ù‡Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø³ÛŒØ§Ø± Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ø¨Ù„Ø§Ú© Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    url = "https://gcaptain.com/feed/" 
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        # Ø¨Ø±Ø§ÛŒ RSS Ø§Ø² ÙØ±Ù…Øª xml Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        soup = BeautifulSoup(response.content, 'xml')
        
        # Ø¯Ø± RSS ØªÛŒØªØ±Ù‡Ø§ Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø§Ø®Ù„ ØªÚ¯ <title> Ù‡Ø³ØªÙ†Ø¯
        headlines = [item.text.strip() for item in soup.find_all('title')]
        
        # ØªÛŒØªØ± Ø§ÙˆÙ„ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ù†Ø§Ù… Ø®ÙˆØ¯ Ø³Ø§ÛŒØª Ø§Ø³ØªØŒ Ø§Ø² Ø¯ÙˆÙ…ÛŒ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        actual_news = headlines[1:6] 
        
        if not actual_news:
            print("âŒ Still blocked or empty. Let's use Simulated Data for now.")
            return None
        else:
            print(f"âœ… Success! Mined {len(actual_news)} live headlines:")
            for i, h in enumerate(actual_news, 1):
                print(f"{i}. {h}")
            return actual_news
                
    except Exception as e:
        print(f"âš ï¸ Error: {e}")
        return None

if __name__ == "__main__":
    test_fetch_rss()